{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from analysis.models import EncodeDataset\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4506"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EncodeDataset.objects.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fn = os.path.abspath('./data/private/bigWigFiles.txt')\n",
    "fn = os.path.abspath('data/bigWigFiles.txt')\n",
    "assert os.path.exists(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using list instead of dict because of duplicate file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFileLocationList(fn):\n",
    "    files = open(fn, 'r').readlines()\n",
    "    filenames = [f.strip() for f in files]\n",
    "    fns = []\n",
    "    for file_ in filenames:\n",
    "        #fns[os.path.basename(file_)] = file_\n",
    "        fns.append({\"base_name\":os.path.basename(file_), \"full_path\":file_})\n",
    "    return fns\n",
    "\n",
    "#fns = getFileLocationDict(fn)\n",
    "fns = getFileLocationList(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5613"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are files with no identifying md5sum values in metadata.  However, none of these files have duplicated file names.  This likely needs to be checked when additional ENCODE files are added or the ENCODE data is updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ds in EncodeDataset.objects.all():\n",
    "    if ds.data_ambiguous:        \n",
    "        if \"ambig_md5sum\" not in ds.extra_content:\n",
    "            count = 0\n",
    "            for entry_ in fns:\n",
    "                if os.path.basename(ds.data_ambiguous.path) == entry_[\"base_name\"]:\n",
    "                    count += 1\n",
    "            if count > 1:\n",
    "                print(\"Duplicate file name exists with no md5sum!!\")\n",
    "    if ds.data_plus:\n",
    "        #assert \"plus_md5sum\" in ds.extra_content\n",
    "        if \"plus_md5sum\" not in ds.extra_content:\n",
    "            count = 0\n",
    "            for entry_ in fns:\n",
    "                if os.path.basename(ds.data_plus.path) == entry_[\"base_name\"]:\n",
    "                    count += 1\n",
    "            if count > 1:\n",
    "                print(\"Duplicate file name exists with no md5sum!!\")\n",
    "    if ds.data_minus:\n",
    "        #assert \"minus_md5sum\" in ds.extra_content\n",
    "        if \"minus_md5sum\" not in ds.extra_content:\n",
    "            count = 0\n",
    "            for entry_ in fns:\n",
    "                if os.path.basename(ds.data_minus.path) == entry_[\"base_name\"]:\n",
    "                    count += 1\n",
    "            if count > 1:\n",
    "                print(\"Duplicate file name exists with no md5sum!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "md5sum_fn = os.path.abspath('data/md5list.txt')\n",
    "assert os.path.exists(md5sum_fn)\n",
    "\n",
    "def getMd5SumDict(fn):\n",
    "    lines = open(fn, 'r').readlines()\n",
    "    md5sums = []\n",
    "    for line_ in lines:\n",
    "        #fns[os.path.basename(file_)] = file_\n",
    "        md5sums.append({\"md5sum\":line_.split()[0], \"full_path\":line_.strip().split()[1]})\n",
    "    return md5sums\n",
    "\n",
    "md5sums = getMd5SumDict(md5sum_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5613"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md5sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'md5sum': 'b8d2f64650efaf479de2e5400a730a9c', 'full_path': '/apps/encodeTracks/mm9/wgEncodeCaltechHist/wgEncodeCaltechHistC2c12Ab2621FCntrl50bPcr1xSigRep1.bigWig'}\n"
     ]
    }
   ],
   "source": [
    "print(md5sums[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def findMatchingFilePath(file_name, file_md5sum, fns, md5sums):\n",
    "    #file_name = os.path.basename(ds.data_ambiguous.path)\n",
    "    if file_md5sum:\n",
    "        for entry_ in md5sums:\n",
    "            if file_md5sum == entry_[\"md5sum\"]:\n",
    "                return entry_[\"full_path\"]\n",
    "    else:\n",
    "        matching_files = []\n",
    "        for entry_ in fns:\n",
    "            if file_name == entry_[\"base_name\"]:\n",
    "                matching_files.append(entry_[\"full_path\"])\n",
    "        if len(matching_files) == 1:\n",
    "            return matching_files[0]\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "for ds in EncodeDataset.objects.all():\n",
    "    \n",
    "    if ds.data_ambiguous:\n",
    "        if \"ambig_md5sum\" in ds.extra_content:\n",
    "            ds.data_ambiguous = findMatchingFilePath(os.path.basename(ds.data_ambiguous.path), ds.extra_content[\"ambig_md5sum\"], fns, md5sums)\n",
    "        else:\n",
    "            ds.data_ambiguous = findMatchingFilePath(os.path.basename(ds.data_ambiguous.path), False, fns, md5sums)\n",
    "    if ds.data_plus:\n",
    "        #ds.data_plus = findMatchingFilePath(os.path.basename(ds.data_plus.path), ds.extra_content[\"plus_md5sum\"], fns, md5sums)\n",
    "        if \"plus_md5sum\" in ds.extra_content:\n",
    "            ds.data_plus = findMatchingFilePath(os.path.basename(ds.data_plus.path), ds.extra_content[\"plus_md5sum\"], fns, md5sums)\n",
    "        else:\n",
    "            ds.data_plus = findMatchingFilePath(os.path.basename(ds.data_plus.path), False, fns, md5sums)\n",
    "    if ds.data_minus:\n",
    "        #ds.data_minus = findMatchingFilePath(os.path.basename(ds.data_minus.path), ds.extra_content[\"minus_md5sum\"], fns, md5sums)\n",
    "        if \"minus_md5sum\" in ds.extra_content:\n",
    "            ds.data_ambiguous = findMatchingFilePath(os.path.basename(ds.data_minus.path), ds.extra_content[\"minus_md5sum\"], fns, md5sums)\n",
    "        else:\n",
    "            ds.data_ambiguous = findMatchingFilePath(os.path.basename(ds.data_minus.path), False, fns, md5sums)\n",
    "        \n",
    "    #ds.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def checkFile(file_name):\n",
    "    match_count = 0\n",
    "    for entry_ in fns:\n",
    "        if file_name == entry_[\"full_path\"]:\n",
    "            match_count += 1\n",
    "    if match_count != 1:\n",
    "        print(\"Full path not present in file list!!\")\n",
    "\n",
    "for ds in EncodeDataset.objects.all():\n",
    "    if ds.data_ambiguous:\n",
    "        checkFile(ds.data_ambiguous)\n",
    "    if ds.data_plus:\n",
    "        checkFile(ds.data_plus)\n",
    "    if ds.data_minus:\n",
    "        checkFile(ds.data_minus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
