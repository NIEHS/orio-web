{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ENCODE import JSON\n",
    "\n",
    "Create a JSON file to import ENCODE data into the web applicaiton using the command:\n",
    "\n",
    "    python manage.py load_encode /path/to/encode_json.json\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from django.conf import settings\n",
    "\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = os.path.abspath('./data/cleaned_encode_list.xlsx')\n",
    "assert os.path.exists(fn)\n",
    "df = pd.read_excel(fn, sheetname=\"Metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "md5_fn = os.path.abspath('data/md5list.txt')\n",
    "assert os.path.exists(md5_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create list with local file paths\n",
    "\n",
    "We have a list of bigWig files and md5 values for all files. We now need to map these files to our mapping in this Excel crosswalk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encode_root = \"/apps/encodeTracks/\"\n",
    "def getFileLocationDict(fn):\n",
    "    cw = defaultdict(dict)\n",
    "    \n",
    "    with open(fn, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    lines = [ln.split() for ln in lines]\n",
    "    \n",
    "    for md5, fn in lines:\n",
    "        name = os.path.basename(fn)\n",
    "        path = fn.replace(encode_root, '')  # remove root\n",
    "        cw[name][md5] = path\n",
    "    \n",
    "    return cw\n",
    "\n",
    "cw = getFileLocationDict(md5_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMatchingPath(name, md5=None):\n",
    "    files = cw[name]\n",
    "    \n",
    "    # first, see if we're missing a name in the crosswalk\n",
    "    if len(files) == 0:\n",
    "        return print('Missing name: {}'.format(name))\n",
    "    \n",
    "    # first, try to get using MD5        \n",
    "    try:\n",
    "        return files[md5]\n",
    "    except Exception:\n",
    "        if md5:\n",
    "            # next, see if we're not matching an MD5\n",
    "            print('Unmatched MD5: {} - our MD5: {}, from db: {}'.format(\n",
    "                name, md5, '|'.join(files.keys())\n",
    "            ))        \n",
    "    \n",
    "    # next, if no MD5 but only one name, use this value\n",
    "    if len(files) == 1 and md5 is None:\n",
    "        return list(files.values())[0]\n",
    "    \n",
    "    print('Unmatched: {} {}'.format(name, md5))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def func(d, fld, md5fld):\n",
    "    name = d[fld]\n",
    "    md5 = d[md5fld]\n",
    "    if md5 is np.NaN:\n",
    "        md5 = None\n",
    "    if name is not np.NaN:\n",
    "        path = getMatchingPath(name, md5)\n",
    "        if path:\n",
    "            return path\n",
    "    return None\n",
    "\n",
    "df['_plus_bigwig_fn'] = df.apply(func, axis=1, args=('plus_bigwig', 'plus_md5sum'))\n",
    "df['_minus_bigwig_fn'] = df.apply(func, axis=1, args=('minus_bigwig', 'minus_md5sum'))\n",
    "df['_ambig_bigwig_fn'] = df.apply(func, axis=1, args=('ambig_bigwig', 'ambig_md5sum'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup content in Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make text field NaN = \"\"\n",
    "fields = [\n",
    "    #'Name',\n",
    "    'Description',\n",
    "    #'plus_bigwig',\n",
    "    #'minus_bigwig',\n",
    "    #'ambig_bigwig',\n",
    "    #'genome_assembly',\n",
    "    #'dataType',\n",
    "    'cell',\n",
    "    'antibody',\n",
    "    'rnaExtract',\n",
    "    'phase',\n",
    "    'treatment',\n",
    "    'localization',\n",
    "    'labExpId',\n",
    "    'dccAccession',\n",
    "    'controlId',\n",
    "    'project'\n",
    "    'labExpId',\n",
    "    'dccAccession',\n",
    "    'controlId',\n",
    "    'project',\n",
    "    'ambig_md5sum',\n",
    "    'ambig_view',\n",
    "    #'subId',\n",
    "    'protocol',\n",
    "    #'replicate',\n",
    "    'lab',\n",
    "    #'type',\n",
    "    'ambig_tableName',\n",
    "    'geoSampleAccession',\n",
    "    'setType',\n",
    "    #'dateUnrestricted',\n",
    "    #'dataVersion',\n",
    "    'ambig_size',\n",
    "    'composite',\n",
    "    #'grant',\n",
    "    #'dateSubmitted',\n",
    "    'origAssembly',\n",
    "    'labVersion',\n",
    "    'control',\n",
    "    #'dateResubmitted',\n",
    "    'plus_md5sum',\n",
    "    'readType',\n",
    "    'plus_tableName',\n",
    "    'plus_view',\n",
    "    'minus_md5sum',\n",
    "    'minus_tableName',\n",
    "    'minus_size',\n",
    "    'plus_size',\n",
    "    'donorId',\n",
    "    'bioRep',\n",
    "    'minus_view',\n",
    "    'seqPlatform',\n",
    "    'spikeInPool',\n",
    "    'sex',\n",
    "    'mapAlgorithm',\n",
    "    'platform',\n",
    "    'submittedDataVersion',\n",
    "    #'insertLength',\n",
    "    #'expId',\n",
    "    'labProtocolId',\n",
    "    'uniqueness',\n",
    "    'sourceObj',\n",
    "    'softwareVersion',\n",
    "    'age',\n",
    "    'strain',\n",
    "    'tissueSourceType',\n",
    "\n",
    "]\n",
    "for fld in fields:\n",
    "    if fld not in df.columns:\n",
    "        continue\n",
    "    df[fld].fillna(value='', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert date fields to ordinal\n",
    "def func(d, fld):\n",
    "    val = d[fld]\n",
    "    if val is not np.NaN and val is not pd.NaT:\n",
    "        try:\n",
    "            return val.toordinal()\n",
    "        except AttributeError:\n",
    "            # invalid date\n",
    "            print(\"Invalid date: {}\".format(val))\n",
    "    return None\n",
    "\n",
    "df['dateUnrestricted'] = df.apply(func, axis=1, args=('dateUnrestricted', ))\n",
    "df['dateSubmitted'] = df.apply(func, axis=1, args=('dateSubmitted', ))\n",
    "df['dateResubmitted'] = df.apply(func, axis=1, args=('dateResubmitted', ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For numeric fields, set NaN to None\n",
    "fields = [\n",
    "    'subId',\n",
    "    'replicate',\n",
    "    'dataVersion',\n",
    "    'insertLength',\n",
    "    'expId',\n",
    "    'dateUnrestricted',\n",
    "    'dateSubmitted',\n",
    "    'dateResubmitted',\n",
    "]\n",
    "for fld in fields:\n",
    "    df[fld] = df[fld].where(pd.notnull(df[fld]), other=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coerce to string (some datetimes mixed in)\n",
    "df['dataVersion'] = df.dataVersion.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create extra content field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extra_content_fields = [\n",
    "    'labExpId',\n",
    "    'dccAccession',\n",
    "    'controlId',\n",
    "    'project',\n",
    "    'ambig_md5sum',\n",
    "    'ambig_view',\n",
    "    'subId',\n",
    "    'protocol',\n",
    "    'replicate',\n",
    "    'lab',\n",
    "    'type',\n",
    "    'ambig_tableName',\n",
    "    'geoSampleAccession',\n",
    "    'setType',\n",
    "    'dateUnrestricted',\n",
    "    'dataVersion',\n",
    "    'ambig_size',\n",
    "    'composite',\n",
    "    'grant',\n",
    "    'dateSubmitted',\n",
    "    'origAssembly',\n",
    "    'labVersion',\n",
    "    'control',\n",
    "    'dateResubmitted',\n",
    "    'plus_md5sum',\n",
    "    'readType',\n",
    "    'plus_tableName',\n",
    "    'plus_view',\n",
    "    'minus_md5sum',\n",
    "    'minus_tableName',\n",
    "    'minus_size',\n",
    "    'plus_size',\n",
    "    'donorId',\n",
    "    'bioRep',\n",
    "    'minus_view',\n",
    "    'seqPlatform',\n",
    "    'spikeInPool',\n",
    "    'sex',\n",
    "    'mapAlgorithm',\n",
    "    'platform',\n",
    "    'submittedDataVersion',\n",
    "    'insertLength',\n",
    "    'expId',\n",
    "    'labProtocolId',\n",
    "    'uniqueness',\n",
    "    'sourceObj',\n",
    "    'softwareVersion',\n",
    "    'age',\n",
    "    'strain',\n",
    "    'tissueSourceType',\n",
    "]\n",
    "\n",
    "dtype_datetime = np.dtype('datetime64[ns]')\n",
    "\n",
    "def getExtraContent(d):\n",
    "    content = {}\n",
    "    for fld in extra_content_fields:\n",
    "        val = d[fld]\n",
    "        if val and val is not pd.NaT:\n",
    "            if df[fld].dtype is dtype_datetime:\n",
    "                content[fld] = d[fld].toordinal()\n",
    "            elif val is not np.NaN:\n",
    "                content[fld] = d[fld]\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create JSON file for import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dicts = []\n",
    "for i, d in df.iterrows():\n",
    "    extra_content = getExtraContent(d)\n",
    "    d = {\n",
    "        \"name\": d.Name,\n",
    "        \"genome_assembly\": d.genome_assembly,\n",
    "        \"data_type\": d.dataType,\n",
    "        \"cell_type\": d.cell,\n",
    "        \"antibody\": d.antibody,\n",
    "        \"rna_extract\": d.rnaExtract,\n",
    "        \"treatment\": d.treatment,\n",
    "        \"phase\": d.phase,\n",
    "        \"localization\": d.localization,\n",
    "        \"extra_content\": extra_content,\n",
    "        \"plus_bigwig\": d._plus_bigwig_fn,\n",
    "        \"minus_bigwig\": d._minus_bigwig_fn,\n",
    "        \"ambig_bigwig\": d._ambig_bigwig_fn,\n",
    "    }\n",
    "    dicts.append(d)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fn = os.path.abspath('./data/load_encode.json')\n",
    "with open(fn, 'w') as f:\n",
    "    f.write(json.dumps(dicts, indent=4, separators=(',', ': ')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
